{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CoUpQ_flQ7hC",
    "outputId": "7cee0c79-fe0a-403a-e991-9ddeb4f5476e"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import vgg16\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcQZ54gzQ7hI"
   },
   "outputs": [],
   "source": [
    "# Path to folders with training data\n",
    "lace_path = Path(\"style_image_clean\") / \"lace\"\n",
    "graphic_path = Path(\"style_image_clean\") / \"graphic\"\n",
    "floral_path = Path(\"style_image_clean\") / \"floral\"\n",
    "stripes_path = Path(\"style_image_clean\") / \"stripes\"\n",
    "pattern_path = Path(\"style_image_clean\") / \"pattern\"\n",
    "pocket_path = Path(\"style_image_clean\") / \"pocket\"\n",
    "print_path = Path(\"style_image_clean\") / \"print\"\n",
    "v_neckline_path = Path(\"style_image_clean\") / \"v-neckline\"\n",
    "\n",
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zDbZvQAkQ7hK"
   },
   "outputs": [],
   "source": [
    "# Load all the lace images\n",
    "for img in lace_path.glob(\"*.jpg\"):\n",
    "    img = image.load_img(img)\n",
    "    image_array = image.img_to_array(img)\n",
    "    images.append(image_array)\n",
    "\n",
    "    # For each 'lace' image, label as 0\n",
    "    labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eco80RhmQ7hN"
   },
   "outputs": [],
   "source": [
    "# Load all the graphic images\n",
    "for img in graphic_path.glob(\"*.jpg\"):\n",
    "    img = image.load_img(img)\n",
    "    image_array = image.img_to_array(img)\n",
    "    images.append(image_array)\n",
    "\n",
    "    # For each 'graphic' image, label as 1\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the floral images\n",
    "for img in floral_path.glob(\"*.jpg\"):\n",
    "    img = image.load_img(img)\n",
    "    image_array = image.img_to_array(img)\n",
    "    images.append(image_array)\n",
    "\n",
    "    # For each 'floral' image, label as 2\n",
    "    labels.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the stripes images\n",
    "for img in stripes_path.glob(\"*.jpg\"):\n",
    "    img = image.load_img(img)\n",
    "    image_array = image.img_to_array(img)\n",
    "    images.append(image_array)\n",
    "\n",
    "    # For each 'stripes' image, label as 3\n",
    "    labels.append(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the pattern images\n",
    "for img in pattern_path.glob(\"*.jpg\"):\n",
    "    img = image.load_img(img)\n",
    "    image_array = image.img_to_array(img)\n",
    "    images.append(image_array)\n",
    "\n",
    "    # For each 'pattern' image, label as 4\n",
    "    labels.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the pocket images\n",
    "for img in pocket_path.glob(\"*.jpg\"):\n",
    "    img = image.load_img(img)\n",
    "    image_array = image.img_to_array(img)\n",
    "    images.append(image_array)\n",
    "\n",
    "    # For each 'pocket' image, label as 5\n",
    "    labels.append(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the print images\n",
    "for img in print_path.glob(\"*.jpg\"):\n",
    "    img = image.load_img(img)\n",
    "    image_array = image.img_to_array(img)\n",
    "    images.append(image_array)\n",
    "\n",
    "    # For each 'print' image, label as 6\n",
    "    labels.append(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the v-neckline images\n",
    "for img in v_neckline_path.glob(\"*.jpg\"):\n",
    "    img = image.load_img(img)\n",
    "    image_array = image.img_to_array(img)\n",
    "    images.append(image_array)\n",
    "\n",
    "    # For each 'print' image, label as 7\n",
    "    labels.append(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "57ElY_liQ7hP"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "images, labels = shuffle(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "roWvcGstQ7hS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_data=to_categorical(y,num_classes=8)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_data, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WD_xmEzQ7hU",
    "outputId": "6436a509-4836-4a75-ee6a-a1db1fa06446"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3654, 256, 256, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 7, 6, ..., 6, 3, 3])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-J3nQ4NQ7hX"
   },
   "outputs": [],
   "source": [
    "X_train = vgg16.preprocess_input(X_train)\n",
    "X_test = vgg16.preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bV_PmCrwQ7hc",
    "outputId": "3260def7-c2ce-45a3-cfaa-8e21d083e069"
   },
   "outputs": [],
   "source": [
    "# Load a pre-trained neural network to use as a feature extractor\n",
    "# set include_top = False to remove the top layer to be replaced by our own classifier\n",
    "base_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "go0DgS3VQ7hf",
    "outputId": "1ff24698-05bf-4dc5-de1e-e964e2a21795"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()\n",
    "#no flatten / ANN layers, coz include_top=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nX5xDRHEQ7hh",
    "outputId": "d2bd58f8-b4ff-4a7b-c3cb-e791d9133870",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 18,934,408\n",
      "Trainable params: 18,934,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the layers in the new classification prediction \n",
    "from tensorflow.keras.models import Model\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)        \n",
    "x = Dense(128, activation='relu')(x)        \n",
    "x = Dense(64, activation='relu')(x)        \n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(8, activation='softmax')(x)  \n",
    "\n",
    "# Define trainable model which links input from the  base model to the new classification prediction layers\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LewwA5TWQ7hk",
    "outputId": "42fd930c-da5a-41c5-a94a-70b5170039c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Transfer Learning\n",
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fce97c511d0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fce97c51c90>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fce3eaf5410>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fce3ea91350>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fce3ea73a50>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fce3eaaf210>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fce3ea685d0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fce3ea61250>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fce3ea71090>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fce3eaaf150>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fce3ea45790>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fce3ea418d0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fce3ea37410>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fcb42f81c50>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fccf43a6fd0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fce3e8c20d0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fce3ea60e90>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fce97cf8fd0>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fcb42f87c50>\n"
     ]
    }
   ],
   "source": [
    "#   Freeze all layers in the vgg16 base model \n",
    "\n",
    "for layer in base_model.layers:\n",
    "    print(layer)\n",
    "    layer.trainable = False\n",
    "#   Define model compile for basic Transfer Learning\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZifPm8NQ7hn",
    "outputId": "2ac43927-be67-4275-e793-2dc95021745d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "457/457 [==============================] - 972s 2s/step - loss: 1.4654 - accuracy: 0.4661 - val_loss: 1.6096 - val_accuracy: 0.4153\n",
      "Epoch 2/5\n",
      "457/457 [==============================] - 967s 2s/step - loss: 1.3955 - accuracy: 0.4893 - val_loss: 1.5824 - val_accuracy: 0.4936\n",
      "Epoch 3/5\n",
      "457/457 [==============================] - 957s 2s/step - loss: 1.2991 - accuracy: 0.5252 - val_loss: 1.6174 - val_accuracy: 0.4853\n",
      "Epoch 4/5\n",
      "457/457 [==============================] - 963s 2s/step - loss: 1.2401 - accuracy: 0.5435 - val_loss: 1.5343 - val_accuracy: 0.5192\n",
      "Epoch 5/5\n",
      "457/457 [==============================] - 971s 2s/step - loss: 1.1678 - accuracy: 0.5761 - val_loss: 1.5227 - val_accuracy: 0.4720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc8f3680590>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    batch_size=8,\n",
    "    validation_data=(X_test,y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GQAWcs53Q7iQ"
   },
   "source": [
    "## Tuning -  Using ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GngQhGcMQ7iR",
    "outputId": "f3e6c8b8-4970-40e0-ce16-d825366485f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "456/456 [==============================] - 927s 2s/step - loss: 1.7840 - accuracy: 0.3683 - val_loss: 1.4568 - val_accuracy: 0.5053\n",
      "Epoch 2/30\n",
      "456/456 [==============================] - 909s 2s/step - loss: 1.6102 - accuracy: 0.4221 - val_loss: 1.4563 - val_accuracy: 0.5158\n",
      "Epoch 3/30\n",
      "456/456 [==============================] - 917s 2s/step - loss: 1.5567 - accuracy: 0.4493 - val_loss: 1.3871 - val_accuracy: 0.5292\n",
      "Epoch 4/30\n",
      "456/456 [==============================] - 963s 2s/step - loss: 1.5421 - accuracy: 0.4509 - val_loss: 1.4190 - val_accuracy: 0.5103\n",
      "Epoch 5/30\n",
      "456/456 [==============================] - 1030s 2s/step - loss: 1.4955 - accuracy: 0.4649 - val_loss: 1.3778 - val_accuracy: 0.5230\n",
      "Epoch 6/30\n",
      "456/456 [==============================] - 893s 2s/step - loss: 1.4890 - accuracy: 0.4841 - val_loss: 1.4343 - val_accuracy: 0.5336\n",
      "Epoch 7/30\n",
      "456/456 [==============================] - 892s 2s/step - loss: 1.4644 - accuracy: 0.4660 - val_loss: 1.4939 - val_accuracy: 0.5242\n",
      "Epoch 8/30\n",
      "456/456 [==============================] - 882s 2s/step - loss: 1.4350 - accuracy: 0.4923 - val_loss: 1.3804 - val_accuracy: 0.5325\n",
      "Epoch 9/30\n",
      "456/456 [==============================] - 894s 2s/step - loss: 1.4198 - accuracy: 0.4871 - val_loss: 1.3622 - val_accuracy: 0.5308\n",
      "Epoch 10/30\n",
      "456/456 [==============================] - 893s 2s/step - loss: 1.4233 - accuracy: 0.4888 - val_loss: 1.3645 - val_accuracy: 0.5536\n",
      "Epoch 11/30\n",
      "456/456 [==============================] - 887s 2s/step - loss: 1.4429 - accuracy: 0.4789 - val_loss: 1.3157 - val_accuracy: 0.5408\n",
      "Epoch 12/30\n",
      "456/456 [==============================] - 890s 2s/step - loss: 1.4379 - accuracy: 0.4863 - val_loss: 1.3723 - val_accuracy: 0.5347\n",
      "Epoch 13/30\n",
      "456/456 [==============================] - 885s 2s/step - loss: 1.3610 - accuracy: 0.5096 - val_loss: 1.4329 - val_accuracy: 0.5541\n",
      "Epoch 14/30\n",
      "456/456 [==============================] - 883s 2s/step - loss: 1.3855 - accuracy: 0.5159 - val_loss: 1.3689 - val_accuracy: 0.5380\n",
      "Epoch 15/30\n",
      "456/456 [==============================] - 923s 2s/step - loss: 1.3898 - accuracy: 0.5145 - val_loss: 1.3253 - val_accuracy: 0.5358\n",
      "Epoch 16/30\n",
      "456/456 [==============================] - 953s 2s/step - loss: 1.3512 - accuracy: 0.5299 - val_loss: 1.5185 - val_accuracy: 0.5403\n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator(rotation_range=20, zoom_range=0.15,width_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,horizontal_flip=True)\n",
    "\n",
    "H = model.fit_generator(gen.flow(X_train, y_train, batch_size=8),\n",
    "                        validation_data=(X_test,y_test), \n",
    "                        steps_per_epoch=len(X_train) // 8, \n",
    "                        epochs=30,\n",
    "                        callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TransferLearningVGG16-EarlyStopping.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
